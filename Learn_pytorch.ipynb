{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1674, 0.9550, 0.9768],\n",
      "        [0.8886, 0.4494, 0.8122],\n",
      "        [0.2376, 0.4831, 0.4760],\n",
      "        [0.4791, 0.4431, 0.0933],\n",
      "        [0.0960, 0.2594, 0.5854]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "data = [[1, 2],[3, 4]]\n",
    "x_data = torch.tensor(data)\n",
    "print(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)\n",
    "print(x_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor: \n",
      " tensor([[1, 1],\n",
      "        [1, 1]]) \n",
      "\n",
      "Random Tensor: \n",
      " tensor([[0.0316, 0.1235],\n",
      "        [0.9903, 0.6996]]) \n",
      "\n",
      "ones float Tensor : \n",
      " tensor([[1., 1.],\n",
      "        [1., 1.]]) \n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "\"check_uniform_bounds\" not implemented for 'Bool'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-fa1a26fac78b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mx_bools\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"bools Tensor : \\n {x_bools} \\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \"check_uniform_bounds\" not implemented for 'Bool'"
     ]
    }
   ],
   "source": [
    "x_ones = torch.ones_like(x_data) # retains the properties of x_data\n",
    "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
    "\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data\n",
    "print(f\"Random Tensor: \\n {x_rand} \\n\")\n",
    "\n",
    "x_ones_float = torch.ones_like(x_data, dtype=torch.float)\n",
    "print(f\"ones float Tensor : \\n {x_ones_float} \\n\")\n",
    "\n",
    "\n",
    "x_bools = torch.rand_like(x_data, dtype=torch.bool)\n",
    "print(f\"bools Tensor : \\n {x_bools} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " 'is_complex',\n",
       " 'is_floating_point',\n",
       " 'is_signed']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(torch.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(145460, 23)\n",
      "        Rainfall  Humidity9am  Pressure9am  RainToday  RainTomorrow\n",
      "0            0.6         71.0       1007.7        0.0           0.0\n",
      "1            0.0         44.0       1010.6        0.0           0.0\n",
      "2            0.0         38.0       1007.6        0.0           0.0\n",
      "3            0.0         45.0       1017.6        0.0           0.0\n",
      "4            1.0         82.0       1010.8        0.0           0.0\n",
      "...          ...          ...          ...        ...           ...\n",
      "145455       0.0         51.0       1024.6        0.0           0.0\n",
      "145456       0.0         56.0       1023.5        0.0           0.0\n",
      "145457       0.0         53.0       1021.0        0.0           0.0\n",
      "145458       0.0         51.0       1019.4        0.0           0.0\n",
      "145459       0.0         62.0       1020.2        0.0           NaN\n",
      "\n",
      "[145460 rows x 5 columns]\n",
      "X_train : \n",
      "tensor([[1.4200e+01, 9.4000e+01, 1.0241e+03, 1.0000e+00],\n",
      "        [0.0000e+00, 5.2000e+01, 1.0118e+03, 0.0000e+00],\n",
      "        [2.0000e-01, 8.7000e+01, 1.0182e+03, 0.0000e+00],\n",
      "        ...,\n",
      "        [0.0000e+00, 8.5000e+01, 1.0211e+03, 0.0000e+00],\n",
      "        [0.0000e+00, 5.6000e+01, 9.9870e+02, 0.0000e+00],\n",
      "        [0.0000e+00, 2.8000e+01, 1.0080e+03, 0.0000e+00]])\n",
      "y_train : \n",
      "tensor([1., 0., 0.,  ..., 0., 0., 0.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "df = pd.read_csv('weatherAUS.csv')\n",
    "print(df.shape)\n",
    "cols = ['Rainfall','Humidity9am','Pressure9am','RainToday','RainTomorrow']\n",
    "df = df[cols]\n",
    "\n",
    "df['RainToday'].replace({'No': 0, 'Yes': 1},inplace = True)\n",
    "df['RainTomorrow'].replace({'No': 0, 'Yes': 1},inplace = True)\n",
    "\n",
    "df.dropna(how='any')\n",
    "print(df)\n",
    "\n",
    "sns.countplot(df.RainTomorrow)\n",
    "\n",
    "X_train,X_test, y_train, y_test = train_test_split(df[['Rainfall','Humidity9am','Pressure9am','RainToday']],df['RainTomorrow'], test_size=0.2,random_state=RANDOM_SEED)\n",
    "\n",
    "X_train = torch.from_numpy(X_train.to_numpy()).float()\n",
    "y_train = torch.squeeze(torch.from_numpy(y_train.to_numpy()).float())\n",
    "\n",
    "print(f\"X_train : \\n{X_train}\\ny_train : \\n{y_train}\")\n",
    "\n",
    "X_test = torch.from_numpy(X_test.to_numpy()).float()\n",
    "y_test = torch.squeeze(torch.from_numpy(y_test.to_numpy()).float())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, n_features):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(n_features, 5)\n",
    "        self.fc2 = nn.Linear(5, 3)\n",
    "        self.fc3 = nn.Linear(3, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return torch.sigmoid(self.fc3(x))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device :  cpu\n"
     ]
    }
   ],
   "source": [
    "net = Net(X_train.shape[1])\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "def round_tensor(t, decimal_places=3):\n",
    "    return round(t.item(), decimal_places)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('device : ',device)\n",
    "X_train = X_train.to(device)\n",
    "y_train = y_train.to(device)\n",
    "X_test = X_test.to(device)\n",
    "y_test = y_test.to(device)\n",
    "net = net.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred : \n",
      "tensor([1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "min,max : (tensor(1.0000, grad_fn=<UnbindBackward>), tensor(1., grad_fn=<UnbindBackward>))\n",
      "y_train :\n",
      "tensor([1., 0., 0.,  ..., 0., 0., 0.])\n",
      " min,max : (tensor(0.), tensor(1.))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "all elements of input should be between 0 and 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-139-8453bfde2aff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"y_pred : \\n{y_pred}\\nmin,max : {min(y_pred),max(y_pred)}\\ny_train :\\n{y_train}\\n min,max : {min(y_train),max(y_train)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m       \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    611\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 613\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2760\u001b[0m         \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2762\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_enum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: all elements of input should be between 0 and 1"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(1000):\n",
    "    y_pred = net(X_train)\n",
    "    y_pred = torch.squeeze(y_pred)\n",
    "    print(f\"y_pred : \\n{y_pred}\\nmin,max : {min(y_pred),max(y_pred)}\\ny_train :\\n{y_train}\\n min,max : {min(y_train),max(y_train)}\")\n",
    "    train_loss = criterion(y_pred, y_train)\n",
    "    if epoch % 100 == 0:\n",
    "      train_acc = calculate_accuracy(y_train, y_pred)\n",
    "      y_test_pred = net(X_test)\n",
    "      y_test_pred = torch.squeeze(y_test_pred)\n",
    "      test_loss = criterion(y_test_pred, y_test)\n",
    "      test_acc = calculate_accuracy(y_test, y_test_pred)\n",
    "      print(\n",
    "f'''epoch {epoch}\n",
    "Train set - loss: {round_tensor(train_loss)}, accuracy: {round_tensor(train_acc)}\n",
    "Test  set - loss: {round_tensor(test_loss)}, accuracy: {round_tensor(test_acc)}\n",
    "''')\n",
    "    optimizer.zero_grad()\n",
    "    train_loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function sigmoid:\n",
      "\n",
      "sigmoid(...)\n",
      "    sigmoid(input, *, out=None) -> Tensor\n",
      "    \n",
      "    Returns a new tensor with the sigmoid of the elements of :attr:`input`.\n",
      "    \n",
      "    .. math::\n",
      "        \\text{out}_{i} = \\frac{1}{1 + e^{-\\text{input}_{i}}}\n",
      "    \n",
      "    Args:\n",
      "        input (Tensor): the input tensor.\n",
      "    \n",
      "    Keyword args:\n",
      "        out (Tensor, optional): the output tensor.\n",
      "    \n",
      "    Example::\n",
      "    \n",
      "        >>> a = torch.randn(4)\n",
      "        >>> a\n",
      "        tensor([ 0.9213,  1.0887, -0.8858, -1.7683])\n",
      "        >>> torch.sigmoid(a)\n",
      "        tensor([ 0.7153,  0.7481,  0.2920,  0.1458])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(torch.sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 15)\n",
      "   ID     crim    zn  indus  chas    nox     rm   age     dis  rad  tax  \\\n",
      "0   1  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296   \n",
      "1   2  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242   \n",
      "2   3  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242   \n",
      "3   4  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222   \n",
      "4   5  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222   \n",
      "\n",
      "   ptratio   black  lstat  medv  \n",
      "0     15.3  396.90   4.98  24.0  \n",
      "1     17.8  396.90   9.14  21.6  \n",
      "2     17.8  392.83   4.03  34.7  \n",
      "3     18.7  394.63   2.94  33.4  \n",
      "4     18.7  396.90   5.33  36.2  \n",
      "(404, 13)\n",
      "(102, 13)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-158-4dcfdb7e90a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0moversampdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "input_size = 12\n",
    "hidden_size = 128\n",
    "num_classes = 1 \n",
    "num_epochs = 5\n",
    "learning_rate = 0.001\n",
    "BATCH_SIZE_1 = 101 #train_loader as it has 404 observations\n",
    "BATCH_SIZE_2 = 51 #test_loader as it has 102 observations\n",
    "\n",
    "# setting the path for Data from data/housing folder\n",
    "DATA_FILE_TRAIN = 'Boston.csv'\n",
    "#setting the random seed \n",
    "np.random.seed(42)\n",
    "# Loading the dataset\n",
    "train_data = pd.read_csv(DATA_FILE_TRAIN)\n",
    "print(train_data.shape)\n",
    "print(train_data.head())\n",
    "\n",
    "id_col = ['ID']\n",
    "categorical_features = ['chas'] \n",
    "target_feature = 'medv'\n",
    "\n",
    "dropped_cols = id_col+categorical_features\n",
    "train_data = train_data.drop(dropped_cols, axis=1)\n",
    "all_features = train_data.columns.tolist()  #this will not have 'chas' and 'ID'\n",
    "\n",
    "numerical_features = list(set(all_features)- set([target_feature]))\n",
    "\n",
    "\n",
    "train_data_inp = train_data[numerical_features]\n",
    "train_data_tar = train_data[target_feature]\n",
    "Trn_input,  Val_inp, Trn_target,Val_target = train_test_split(train_data_inp, train_data_tar, test_size=0.2,random_state=123)\n",
    "# Train_data has our training dataset and Valid_data has our validation dataset.\n",
    "Train_data = pd.concat([Trn_input, pd.DataFrame(Trn_target)], axis=1)\n",
    "Valid_data = pd.concat([Val_inp, pd.DataFrame(Val_target)], axis=1)\n",
    "print(Train_data.shape)\n",
    "print(Valid_data.shape)\n",
    "\n",
    "\n",
    "class oversampdata(Dataset):\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self.data = torch.FloatTensor(data.values.astype('float'))\n",
    "        print(self.data.shape)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        target = self.data[index][-1]\n",
    "        data_val = self.data[index] [:-1]\n",
    "        return data_val,target\n",
    "    \n",
    "\n",
    "train_dataset = oversampdata(Train_data)\n",
    "valid_dataset = oversampdata(Valid_data)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if device=='cuda' else {}\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE_1, shuffle=True, **kwargs)\n",
    "test_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE_2, shuffle=True, **kwargs)\n",
    "\n",
    "# Simple Neural network \n",
    "\n",
    "input_size = 12\n",
    "hidden_size = 128\n",
    "num_classes = 1\n",
    "num_epochs = 5\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Neural Network should have a sigmoid activation function if you are using BCELoss()\n",
    "class LinearModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(LinearModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "                           \n",
    "    def get_weights(self):\n",
    "        return self.weight\n",
    "    \n",
    "    def forward(self,x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = F.sigmoid(self.fc2(out)) #sigmoid as we use BCELoss\n",
    "        return out\n",
    "    \n",
    "#TRAINING THE NETWORK\n",
    "def train(model, device, train_loader, optimizer):\n",
    "    model.train()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for i in train_loader:\n",
    "        \n",
    "        #LOADING THE DATA IN A BATCH\n",
    "        data, target = i\n",
    " \n",
    "        #MOVING THE TENSORS TO THE CONFIGURED DEVICE\n",
    "        data, target = data.to(device), target.to(device)\n",
    "       \n",
    "        #FORWARD PASS\n",
    "        output = model(data.float())\n",
    "        loss = criterion(output, target.unsqueeze(1)) \n",
    "        \n",
    "        #BACKWARD AND OPTIMIZE\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # PREDICTIONS \n",
    "        pred = np.round(output.detach())\n",
    "        target = np.round(target.detach())            \n",
    "        y_pred.extend(pred.tolist())\n",
    "        y_true.extend(target.tolist())\n",
    "        \n",
    "    print(\"Accuracy on training set is\" ,accuracy_score(y_true,y_pred))\n",
    "\n",
    "                          \n",
    "#TESTING THE MODEL\n",
    "def test(model, device, test_loader):\n",
    "    #model in eval mode skips Dropout etc\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    # set the requires_grad flag to false as we are in the test mode\n",
    "    with torch.no_grad():\n",
    "        for i in test_loader:\n",
    "            \n",
    "            #LOAD THE DATA IN A BATCH\n",
    "            data,target = i\n",
    "            \n",
    "            # moving the tensors to the configured device\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            # the model on the data\n",
    "            output = model(data.float())\n",
    "                       \n",
    "            #PREDICTIONS\n",
    "            pred = np.round(output)\n",
    "            target = target.float()\n",
    "            y_true.extend(target.tolist()) \n",
    "            y_pred.extend(pred.reshape(-1).tolist())\n",
    "    \n",
    "            \n",
    "    print(\"Accuracy on test set is\" , accuracy_score(y_true,y_pred))\n",
    "    print(\"***********************************************************\")\n",
    "                          \n",
    "\n",
    "\n",
    "# Creating model and setting loss and optimizer.\n",
    "model = LinearModel(input_size, hidden_size, num_classes).to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "                          \n",
    "for epoch in range(num_epochs):\n",
    "        train(model,device,BATCH_SIZE_1,optimizer)\n",
    "        test(model,device,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function dropna in module pandas.core.frame:\n",
      "\n",
      "dropna(self, axis=0, how='any', thresh=None, subset=None, inplace=False)\n",
      "    Remove missing values.\n",
      "    \n",
      "    See the :ref:`User Guide <missing_data>` for more on which values are\n",
      "    considered missing, and how to work with missing data.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      "        Determine if rows or columns which contain missing values are\n",
      "        removed.\n",
      "    \n",
      "        * 0, or 'index' : Drop rows which contain missing values.\n",
      "        * 1, or 'columns' : Drop columns which contain missing value.\n",
      "    \n",
      "        .. versionchanged:: 1.0.0\n",
      "    \n",
      "           Pass tuple or list to drop on multiple axes.\n",
      "           Only a single axis is allowed.\n",
      "    \n",
      "    how : {'any', 'all'}, default 'any'\n",
      "        Determine if row or column is removed from DataFrame, when we have\n",
      "        at least one NA or all NA.\n",
      "    \n",
      "        * 'any' : If any NA values are present, drop that row or column.\n",
      "        * 'all' : If all values are NA, drop that row or column.\n",
      "    \n",
      "    thresh : int, optional\n",
      "        Require that many non-NA values.\n",
      "    subset : array-like, optional\n",
      "        Labels along other axis to consider, e.g. if you are dropping rows\n",
      "        these would be a list of columns to include.\n",
      "    inplace : bool, default False\n",
      "        If True, do operation inplace and return None.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    DataFrame\n",
      "        DataFrame with NA entries dropped from it.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    DataFrame.isna: Indicate missing values.\n",
      "    DataFrame.notna : Indicate existing (non-missing) values.\n",
      "    DataFrame.fillna : Replace missing values.\n",
      "    Series.dropna : Drop missing values.\n",
      "    Index.dropna : Drop missing indices.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> df = pd.DataFrame({\"name\": ['Alfred', 'Batman', 'Catwoman'],\n",
      "    ...                    \"toy\": [np.nan, 'Batmobile', 'Bullwhip'],\n",
      "    ...                    \"born\": [pd.NaT, pd.Timestamp(\"1940-04-25\"),\n",
      "    ...                             pd.NaT]})\n",
      "    >>> df\n",
      "           name        toy       born\n",
      "    0    Alfred        NaN        NaT\n",
      "    1    Batman  Batmobile 1940-04-25\n",
      "    2  Catwoman   Bullwhip        NaT\n",
      "    \n",
      "    Drop the rows where at least one element is missing.\n",
      "    \n",
      "    >>> df.dropna()\n",
      "         name        toy       born\n",
      "    1  Batman  Batmobile 1940-04-25\n",
      "    \n",
      "    Drop the columns where at least one element is missing.\n",
      "    \n",
      "    >>> df.dropna(axis='columns')\n",
      "           name\n",
      "    0    Alfred\n",
      "    1    Batman\n",
      "    2  Catwoman\n",
      "    \n",
      "    Drop the rows where all elements are missing.\n",
      "    \n",
      "    >>> df.dropna(how='all')\n",
      "           name        toy       born\n",
      "    0    Alfred        NaN        NaT\n",
      "    1    Batman  Batmobile 1940-04-25\n",
      "    2  Catwoman   Bullwhip        NaT\n",
      "    \n",
      "    Keep only the rows with at least 2 non-NA values.\n",
      "    \n",
      "    >>> df.dropna(thresh=2)\n",
      "           name        toy       born\n",
      "    1    Batman  Batmobile 1940-04-25\n",
      "    2  Catwoman   Bullwhip        NaT\n",
      "    \n",
      "    Define in which columns to look for missing values.\n",
      "    \n",
      "    >>> df.dropna(subset=['name', 'born'])\n",
      "           name        toy       born\n",
      "    1    Batman  Batmobile 1940-04-25\n",
      "    \n",
      "    Keep the DataFrame with valid entries in the same variable.\n",
      "    \n",
      "    >>> df.dropna(inplace=True)\n",
      "    >>> df\n",
      "         name        toy       born\n",
      "    1  Batman  Batmobile 1940-04-25\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "help(pd.DataFrame.dropna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
