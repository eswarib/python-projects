{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 15)\n",
      "   ID     crim    zn  indus  chas    nox     rm   age     dis  rad  tax  \\\n",
      "0   1  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296   \n",
      "1   2  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242   \n",
      "2   3  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242   \n",
      "3   4  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222   \n",
      "4   5  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222   \n",
      "\n",
      "   ptratio   black  lstat  medv  \n",
      "0     15.3  396.90   4.98  24.0  \n",
      "1     17.8  396.90   9.14  21.6  \n",
      "2     17.8  392.83   4.03  34.7  \n",
      "3     18.7  394.63   2.94  33.4  \n",
      "4     18.7  396.90   5.33  36.2  \n"
     ]
    }
   ],
   "source": [
    "# setting the path for Data from data/housing folder\n",
    "DATA_FILE_TRAIN = 'Boston.csv'\n",
    "#setting the random seed \n",
    "np.random.seed(42)\n",
    "# Loading the dataset\n",
    "train_data = pd.read_csv(DATA_FILE_TRAIN)\n",
    "print(train_data.shape)\n",
    "print(train_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE_1 = 101\n",
    "BATCH_SIZE_2 = 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.0\n",
      "5.0\n"
     ]
    }
   ],
   "source": [
    "# To decide on the bin values\n",
    "print(train_data['medv'].max())\n",
    "print(train_data['medv'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID     crim    zn  indus  chas    nox     rm   age     dis  rad  tax  \\\n",
      "0   1  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296   \n",
      "1   2  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242   \n",
      "2   3  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242   \n",
      "3   4  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222   \n",
      "4   5  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222   \n",
      "\n",
      "   ptratio   black  lstat medv  \n",
      "0     15.3  396.90   4.98    0  \n",
      "1     17.8  396.90   9.14    0  \n",
      "2     17.8  392.83   4.03    1  \n",
      "3     18.7  394.63   2.94    1  \n",
      "4     18.7  396.90   5.33    1  \n",
      "15\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bins = [0,30,50]\n",
    "labels = [0,1]\n",
    "train_data['medv'] = pd.cut(train_data['medv'], bins=bins, labels=labels)\n",
    "print(train_data.head())\n",
    "print(len(train_data.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The target class ratio is Counter({0: 422, 1: 84})\n"
     ]
    }
   ],
   "source": [
    "print(f\"The target class ratio is {Counter(train_data['medv']) }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_col = ['ID']\n",
    "categorical_features = ['chas'] \n",
    "target_feature = 'medv'\n",
    "\n",
    "dropped_cols = id_col+categorical_features\n",
    "train_data = train_data.drop(dropped_cols, axis=1)\n",
    "all_features = train_data.columns.tolist()  #this will not have 'chas' and 'ID'\n",
    "\n",
    "numerical_features = list(set(all_features)- set([target_feature]))\n",
    "#print(len(numerical_features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404, 13)\n",
      "(102, 13)\n"
     ]
    }
   ],
   "source": [
    "train_data_inp = train_data[numerical_features]\n",
    "train_data_tar = train_data[target_feature]\n",
    "Trn_input,  Val_inp, Trn_target,Val_target = train_test_split(train_data_inp, train_data_tar, test_size=0.2,random_state=123)\n",
    "# Train_data has our training dataset and Valid_data has our validation dataset.\n",
    "Train_data = pd.concat([Trn_input, pd.DataFrame(Trn_target)], axis=1)\n",
    "Valid_data = pd.concat([Val_inp, pd.DataFrame(Val_target)], axis=1)\n",
    "print(Train_data.shape)\n",
    "print(Valid_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class oversampdata(Dataset):\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self.data = torch.FloatTensor(data.values.astype('float'))\n",
    "        print(self.data.shape)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        target = self.data[index][-1]\n",
    "        data_val = self.data[index] [:-1]\n",
    "        return data_val,target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([404, 13])\n",
      "torch.Size([102, 13])\n"
     ]
    }
   ],
   "source": [
    "# training and validation dataset \n",
    "train_dataset = oversampdata(Train_data)\n",
    "valid_dataset = oversampdata(Valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if device=='cuda' else {}\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE_1, shuffle=True, **kwargs)\n",
    "test_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE_2, shuffle=True, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Neural network \n",
    "\n",
    "input_size = 12\n",
    "hidden_size = 128\n",
    "num_classes = 1\n",
    "num_epochs = 5\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using BCE Loss( )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network should have a sigmoid activation function if you are using BCELoss()\n",
    "\n",
    "class LinearModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(LinearModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "                    \n",
    "    def get_weights(self):\n",
    "        return self.weight\n",
    "    \n",
    "    def forward(self,x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = torch.sigmoid(self.fc2(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAINING THE NETWORK\n",
    "def train(model,device,train_loader,optimizer):\n",
    "    model.train()\n",
    "    loss_total = 0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for i in train_loader:\n",
    "        \n",
    "        #LOADING THE DATA IN A BATCH\n",
    "        data, target = i\n",
    "         \n",
    "        # moving the tensors to the configured device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        #print(data.shape, target.shape)\n",
    "        \n",
    "        #FORWARD PASS\n",
    "        output = model(data.float())\n",
    "        print('printing the ')\n",
    "        loss = criterion(output, target.unsqueeze(1)) \n",
    "        \n",
    "        # calculating the total_loss for checking\n",
    "        loss_total += loss\n",
    "        \n",
    "        #BACKWARD AND OPTIMIZE\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # PREDICTIONS \n",
    "       \n",
    "        pred = np.round(output.detach().numpy())\n",
    "        target = target.float()\n",
    "        y_true.extend(target.tolist()) \n",
    "        y_pred.extend(pred.reshape(-1).tolist())\n",
    "        \n",
    "\n",
    "    #print(\" Total Loss is \", loss_total)\n",
    "    print(\"Accuracy on training set is\" , accuracy_score(y_true,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TESTING THE MODEL\n",
    "def test(model, device, test_loader):\n",
    "    #model in eval mode skips Dropout etc\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    # set the requires_grad flag to false as we are in the test mode\n",
    "    with torch.no_grad():\n",
    "        for i in test_loader:\n",
    "            \n",
    "            #LOAD THE DATA IN A BATCH\n",
    "            data,target = i\n",
    "            \n",
    "            # moving the tensors to the configured device\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            # Create model on data\n",
    "            output = model(data.float())\n",
    "                       \n",
    "            #PREDICTIONS\n",
    "            pred = np.round(output)\n",
    "            target = target.float()\n",
    "            y_true.extend(target.tolist()) \n",
    "            y_pred.extend(pred.reshape(-1).tolist())\n",
    "    \n",
    "            \n",
    "    print(\"Accuracy on test set is\" , accuracy_score(y_true,y_pred))\n",
    "    print(\"***********************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating model and setting loss and optimizer.\n",
    "model = LinearModel(input_size, hidden_size, num_classes).to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set is 0.844059405940594\n",
      "Accuracy on test set is 0.7941176470588235\n",
      "***********************************************************\n",
      "Accuracy on training set is 0.7178217821782178\n",
      "Accuracy on test set is 0.5980392156862745\n",
      "***********************************************************\n",
      "Accuracy on training set is 0.7747524752475248\n",
      "Accuracy on test set is 0.803921568627451\n",
      "***********************************************************\n",
      "Accuracy on training set is 0.8514851485148515\n",
      "Accuracy on test set is 0.803921568627451\n",
      "***********************************************************\n",
      "Accuracy on training set is 0.8415841584158416\n",
      "Accuracy on test set is 0.6666666666666666\n",
      "***********************************************************\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "        train(model,device,train_loader,optimizer)\n",
    "        test(model,device,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model checkpoint\n",
    "torch.save(model.state_dict(), 'model_BCSLoss.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
